{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a89b1ca",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Detecting the rectangle of the rice leaf\n",
    "## This pybook is first of the development process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5ac6c51",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7ce58f9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "STD_SIZE: int = 1600\n",
    "\n",
    "\n",
    "def load_image(filepath: str):\n",
    "    file_content = tf.io.read_file(filepath)\n",
    "    image = tf.io.decode_jpeg(file_content, channels=3)  # load in RGB\n",
    "    return tf.image.resize(image, [STD_SIZE, STD_SIZE])  # don't forget to uniform our image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58606705",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-16 20:44:45.393130: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-16 20:44:45.394504: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "import PIL\n",
    "\n",
    "image = load_image(\"RiceLeafs/train/Healthy/IMG_20190419_123623.jpg\")\n",
    "image = tf.cast(image, tf.float32)\n",
    "image = tf.expand_dims(image, 0)\n",
    "\n",
    "sobel = tf.image.sobel_edges(image)\n",
    "sobel_y = np.asarray(sobel[0, :, :, :, 0])  # sobel in y-direction\n",
    "sobel_x = np.asarray(sobel[0, :, :, :, 1])  # sobel in x-direction\n",
    "\n",
    "PIL.Image.fromarray(sobel_y[..., 0]).show()\n",
    "PIL.Image.fromarray(sobel_x[..., 0]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a6483b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "#reading the image\n",
    "image = cv2.imread(\"RiceLeafs/train/Healthy/IMG_20190419_123623.jpg\")\n",
    "image = cv2.resize(image, (1600, 1600))\n",
    "edged = cv2.Canny(image, 10, 220)\n",
    "#cv2.imshow(\"Edges\", edged)\n",
    "#cv2.waitKey(0)\n",
    "\n",
    "#applying closing function\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (7, 7))\n",
    "closed = cv2.morphologyEx(edged, cv2.MORPH_CLOSE, kernel)\n",
    "#cv2.imshow(\"Closed\", closed)\n",
    "#cv2.waitKey(0)\n",
    "\n",
    "#finding_contours\n",
    "(cnts, _) = cv2.findContours(closed.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "for c in cnts:\n",
    "    peri = cv2.arcLength(c, True)\n",
    "    approx = cv2.approxPolyDP(c, 0.02 * peri, True)\n",
    "    cv2.drawContours(image, [approx], -1, (0, 255, 0), 2)\n",
    "cv2.imshow(\"Output\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "148562cb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def find_longest_dicks(contours) -> list:  # distance in contours klist\n",
    "    full_list = []\n",
    "    for c in contours:\n",
    "        peri = cv2.arcLength(c, True)\n",
    "        poly = cv2.approxPolyDP(c, 0.02 * peri, True)\n",
    "        for lin_i in range(len(poly))[:-1]:\n",
    "            full_list.append(((poly[lin_i][0][0], poly[lin_i][0][1]), (poly[lin_i + 1][0][0], poly[lin_i + 1][0][1])))\n",
    "    full_list = sorted(full_list, key=lambda x: -(x[0][0] - x[1][0]) ** 2 - (x[0][1] - x[1][1]) ** 2)\n",
    "    return full_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aecdb839",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6171/2810790340.py:44: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  grad_zero = grad_zero.astype(np.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 255\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from scipy import ndimage\n",
    "import numpy as np\n",
    "import PIL\n",
    "from matplotlib.pyplot import imshow\n",
    "% matplotlib inline\n",
    "\n",
    "scharr = np.array([[1, 1, 1, 1, 1, 1, 1],\n",
    "                   [1, 1, 1, 1, 1, 1, 1],\n",
    "                   [1, 1, 0, 0, 0, 1, 1],\n",
    "                   [1, 1, 0, 0, 0, 1, 1],\n",
    "                   [1, 1, 0, 0, 0, 1, 1],\n",
    "                   [1, 1, 1, 1, 1, 1, 1],\n",
    "                   [1, 1, 1, 1, 1, 1, 1]])\n",
    "\n",
    "sharpen = np.array([[0, 0, 0, -1, 0, 0, 0],\n",
    "                    [0, 0, -1, -1, -1, 0, 0],\n",
    "                    [0, -1, -1, -1, -1, -1, 0],\n",
    "                    [-1, -1, -1, 24, -1, -1, -1],\n",
    "                    [0, -1, -1, -1, -1, -1, 0],\n",
    "                    [0, 0, -1, -1, -1, 0, 0],\n",
    "                    [0, 0, 0, -1, 0, 0, 0]])\n",
    "\n",
    "new_conv = np.array([[0, -1, 0],\n",
    "                     [-1, 5, -1],\n",
    "                     [0, -1, 0]])\n",
    "\n",
    "image = cv2.imread(\"RiceLeafs/train/Healthy/IMG_20190419_123646.jpg\")\n",
    "image = cv2.resize(image, (1600, 1600))\n",
    "no_green_image = image.copy()\n",
    "no_green_image[:, :, 1] = 0\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "grad_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=21)\n",
    "grad_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=21)\n",
    "\n",
    "abs_grad_x = cv2.convertScaleAbs(grad_x)\n",
    "abs_grad_y = cv2.convertScaleAbs(grad_y)\n",
    "\n",
    "grad = np.sqrt(grad_x ** 2 + grad_y ** 2)\n",
    "grad_norm = (grad * 255 / grad.max()).astype(np.uint8)\n",
    "grad_zero = grad_norm.copy()\n",
    "grad_zero[np.abs(grad_zero) < 64] = 0\n",
    "grad_zero = grad_zero.astype(np.float)\n",
    "grad_cnn = ndimage.convolve(grad_zero, sharpen, mode='constant', cval=0.0)\n",
    "grad_cnn[grad_cnn > 255] = 255\n",
    "grad_cnn[grad_cnn < 64] = 0\n",
    "grad_cnn = grad_cnn.astype(np.uint8)\n",
    "print(grad_cnn.min(), grad_cnn.max())\n",
    "\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (7, 7))\n",
    "closed = cv2.morphologyEx(grad_cnn, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "(cnts, _) = cv2.findContours(closed.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "for c in cnts:\n",
    "    peri = cv2.arcLength(c, True)\n",
    "    approx = cv2.approxPolyDP(c, 0.02 * peri, True)\n",
    "    #print(approx, len(approx))\n",
    "    cv2.drawContours(image, [approx], -1, (0, 255, 0), 2)\n",
    "\n",
    "longest = find_longest_dicks(cnts)\n",
    "for line in longest[:2]:\n",
    "    cv2.line(image, line[0], line[1], color=(255, 0, 0), thickness=2)\n",
    "\n",
    "#imshow(cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n",
    "#imshow(image)\n",
    "\n",
    "#grad = cv2.addWeighted(abs_grad_x, 0.5, abs_grad_y, 0.5, 0)\n",
    "\n",
    "#PIL.Image.fromarray(grad_x  ).show()\n",
    "#PIL.Image.fromarray(grad_y  ).show()\n",
    "#PIL.Image.fromarray(grad_norm  ).show()\n",
    "#PIL.Image.fromarray(closed  ).show()\n",
    "PIL.Image.fromarray(image).show()\n",
    "#PIL.Image.fromarray(grad_zero  ).show()\n",
    "#PIL.Image.fromarray(np.absolute(grad_cnn)  ).show()\n",
    "#cv2.imshow('grad X',grad_x)\n",
    "#cv2.imshow('grad Y',grad_y)\n",
    "#cv2.imshow('Sobel Image',grad)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c3bc5b2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'type' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32mC:\\Temp/ipykernel_10408/2077058294.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     22\u001B[0m \u001B[1;31m# b = y2 - k*x2\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     23\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 24\u001B[1;33m \u001B[1;32mdef\u001B[0m \u001B[0mline_koeff\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mline\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mtuple\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mtuple\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mint\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mint\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtuple\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mint\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mint\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[0mtuple\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mfloat\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfloat\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     25\u001B[0m     \u001B[0mk\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mline\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mline\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m/\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mline\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mline\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     26\u001B[0m     \u001B[0mb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mline\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mk\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mline\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: 'type' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import PIL\n",
    "from scipy import ndimage\n",
    "import numpy as np\n",
    "import os\n",
    "from math import sqrt, atan, pi, atan2\n",
    "from sys import stderr\n",
    "\n",
    "\n",
    "def find_longest_dicks(contours) -> list:  # distance in contours klist\n",
    "    full_list = []\n",
    "    for c in contours:\n",
    "        peri = cv2.arcLength(c, True)\n",
    "        poly = cv2.approxPolyDP(c, 0.02 * peri, True)\n",
    "        for lin_i in range(len(poly))[:-1]:\n",
    "            full_list.append(((poly[lin_i][0][0], poly[lin_i][0][1]), (poly[lin_i + 1][0][0], poly[lin_i + 1][0][1])))\n",
    "    full_list = sorted(full_list, key=lambda x: -(x[0][0] - x[1][0]) ** 2 - (x[0][1] - x[1][1]) ** 2)\n",
    "    return full_list\n",
    "\n",
    "\n",
    "# k = (y1 - y2) / (x1 - x2)\n",
    "# b = y2 - k*x2\n",
    "\n",
    "def line_koeff(line: tuple[tuple[int, int], tuple[int, int]]) -> tuple[float, float]:\n",
    "    k = (line[0][1] - line[1][1]) / (line[0][0] - line[1][0])\n",
    "    b = line[1][1] - k * line[1][0]\n",
    "    return k, b\n",
    "\n",
    "\n",
    "def angle_diff(lhs, rhs) -> float:\n",
    "    k_l, _ = line_koeff(lhs)\n",
    "    k_r, _ = line_koeff(rhs)\n",
    "    return abs(atan(k_l) - atan(k_r))\n",
    "\n",
    "def line_len_f(x):\n",
    "    return sqrt((x[0][0] - x[1][0]) ** 2 + (x[0][1] - x[1][1]) ** 2)\n",
    "\n",
    "\n",
    "sharpen_cnn = np.array([[0, 0, 0, -1, 0, 0, 0],\n",
    "                        [0, 0, -1, -1, -1, 0, 0],\n",
    "                        [0, -1, -1, -1, -1, -1, 0],\n",
    "                        [-1, -1, -1, 24, -1, -1, -1],\n",
    "                        [0, -1, -1, -1, -1, -1, 0],\n",
    "                        [0, 0, -1, -1, -1, 0, 0],\n",
    "                        [0, 0, 0, -1, 0, 0, 0]])\n",
    "\n",
    "len_threshold_1 = 0.40\n",
    "len_threshold_other = 0.8\n",
    "angle_diff_threshold = 10 * (pi / 180)\n",
    "OUT_W, OUT_H = 600, 100\n",
    "\n",
    "# TODO compare results with and without shadow removal\n",
    "def shadow_remove(img):\n",
    "    rgb_planes = cv2.split(img)\n",
    "    result_norm_planes = []\n",
    "    for plane in rgb_planes:\n",
    "        dilated_img = cv2.dilate(plane, np.ones((7, 7), np.uint8))\n",
    "        bg_img = cv2.medianBlur(dilated_img, 21)\n",
    "        diff_img = 255 - cv2.absdiff(plane, bg_img)\n",
    "        norm_img = cv2.normalize(diff_img, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8UC1)\n",
    "        result_norm_planes.append(norm_img)\n",
    "    shadowremov = cv2.merge(result_norm_planes)\n",
    "    return shadowremov\n",
    "\n",
    "def find_candidate_lines(image_data) -> list:\n",
    "    #gray = cv2.cvtColor(shadow_remove(image_data), cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.cvtColor(image_data, cv2.COLOR_BGR2GRAY) # TODO cmp\n",
    "\n",
    "    grad_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=21)\n",
    "    grad_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=21)\n",
    "\n",
    "    grad = np.sqrt(grad_x ** 2 + grad_y ** 2)\n",
    "    grad_norm = (grad * 255 / grad.max()).astype(np.uint8)\n",
    "    grad_zero = grad_norm.copy()\n",
    "    grad_zero[np.abs(grad_zero) < 64] = 0\n",
    "    grad_zero = grad_zero.astype(np.float)\n",
    "    grad_cnn = ndimage.convolve(grad_zero, sharpen_cnn, mode='constant', cval=0.0)\n",
    "    grad_cnn[grad_cnn > 255] = 255\n",
    "    grad_cnn[grad_cnn < 64] = 0\n",
    "    grad_cnn = grad_cnn.astype(np.uint8)\n",
    "\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (7, 7))\n",
    "    closed = cv2.morphologyEx(grad_cnn, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    (cnts, _) = cv2.findContours(closed.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    all_dicks = find_longest_dicks(cnts)\n",
    "    longest = all_dicks[:min(10, len(all_dicks))]\n",
    "\n",
    "    # here we filter dicks that are not big enough\n",
    "    if len(longest) <= 2:\n",
    "        return longest\n",
    "    target = list()\n",
    "    target.append(longest[0])  # at least 1 should be here\n",
    "    current_thr = len_threshold_1\n",
    "    for line in longest[1:]:\n",
    "        prev_len = line_len_f(target[-1])\n",
    "        current_len = line_len_f(line)\n",
    "        if current_len < prev_len * current_thr:\n",
    "            break\n",
    "        if angle_diff(target[0], line) > angle_diff_threshold:\n",
    "            continue\n",
    "        target.append(line)\n",
    "        current_thr = len_threshold_other\n",
    "\n",
    "    return target\n",
    "\n",
    "def restrict(x, mn, mx):\n",
    "    return int(max(mn, min(mx, x)))\n",
    "\n",
    "def find_intersection(k1: float, b1: float, k2: float, b2: float, x1: float, size: int) -> tuple[float, float]:\n",
    "    y1 = k1 * x1 + b1\n",
    "    x_r = (y1 + x1 / k1 - b2) / (k2 + 1 / k1)\n",
    "    y_r = x_r * k2 + b2\n",
    "    print(k1, b1, k2, b2, x1, x_r, y_r)\n",
    "    if x_r < -1:\n",
    "        #return int(0), int(b2)\n",
    "        #return find_intersection(k1, b1, k2, b2, x1 - x_r, size)\n",
    "        res = find_intersection(k2, b2, k1, b1, 1, size)\n",
    "        return find_intersection(k1, b1, k2, b2, res[0], size)\n",
    "    elif y_r < -1:\n",
    "        #return int(-b2 / k2), int(0)\n",
    "        #return find_intersection(k1, b1, k2, b2, x1 - y_r / k1, size)\n",
    "        res = find_intersection(k2, b2, k1, b1, (-b2) / k2, size)\n",
    "        return find_intersection(k1, b1, k2, b2, res[0], size)\n",
    "    elif x_r > size:\n",
    "        #return int(size - 1), int((size - 1) * k2 + b2)\n",
    "        #return find_intersection(k1, b1, k2, b2, x1 + (size - x_r), size)\n",
    "        res = find_intersection(k2, b2, k1, b1, (size - 1), size)\n",
    "        return find_intersection(k1, b1, k2, b2, res[0], size)\n",
    "    elif y_r > size:\n",
    "        #return int((size - 1) - b2 / k2), int((size - 1))\n",
    "        #return find_intersection(k1, b1, k2, b2, x1 + (size - y_r) / k1, size)\n",
    "        res = find_intersection(k2, b2, k1, b1, (((size - 1) - b2) / k2), size)\n",
    "        return find_intersection(k1, b1, k2, b2, res[0], size)\n",
    "    return x_r, y_r\n",
    "\n",
    "def spec_atan2(y, x):\n",
    "    res = atan2(y, x)\n",
    "    print(res, y, x)\n",
    "    return res\n",
    "\n",
    "def sort_counterclock(pts: tuple[tuple[int, int], tuple[int, int], tuple[int, int], tuple[int, int]]) -> tuple[tuple[int, int], tuple[int, int], tuple[int, int], tuple[int, int]]:\n",
    "    avg_x, avg_y = (pts[0][0] + pts[1][0] + pts[2][0] + pts[3][0]) / 4, (pts[0][1] + pts[1][1] + pts[2][1] + pts[3][1]) / 4\n",
    "    result = list(pts)\n",
    "    print(\"Points: \", result)\n",
    "    result = sorted(result, key=lambda pt: atan2((pt[0] - avg_x), (pt[1] - avg_y)))\n",
    "    #result = sorted(result, key=lambda pt: spec_atan2((pt[1] - avg_y), (pt[0] - avg_x)))\n",
    "    for pt in result:\n",
    "        print(\"pt({}, {}) from avg({}, {}): atan2 = {}\".format(pt[0], pt[1], avg_x, avg_y, atan2((pt[0] - avg_x), (pt[1] - avg_y))))\n",
    "    if line_len_f((result[0], result[1])) > line_len_f((result[1], result[2])):\n",
    "        return result[1], result[2], result[3], result[0]\n",
    "    return result[0], result[1], result[2], result[3]\n",
    "\n",
    "def normalize_fit_tetragon(tetragon: tuple[tuple[int, int], tuple[int, int], tuple[int, int], tuple[int, int]], size: int) -> tuple[tuple[int, int], tuple[int, int], tuple[int, int], tuple[int, int]]:\n",
    "    result = list()\n",
    "    for x in tetragon:\n",
    "        result.append((min(size, max(0, x[0])), min(size, max(0, x[1]))))\n",
    "    return result[0], result[1], result[2], result[3]\n",
    "\n",
    "def extract_maiha(image: np.ndarray, tetragon: tuple[tuple[int, int], tuple[int, int], tuple[int, int], tuple[int, int]]) -> np.ndarray:\n",
    "    #inp_pts = np.array(tetragon, dtype=float)\n",
    "    # 0231\n",
    "    stetra = sort_counterclock(tetragon)\n",
    "    inp_pts = np.array(stetra, dtype=np.float32)\n",
    "    outp_pts = np.array([[0, 0], [0, OUT_H], [OUT_W, OUT_H], [OUT_W, 0]], dtype=np.float32)\n",
    "    print(inp_pts)\n",
    "    print(outp_pts)\n",
    "    transform_mat = cv2.getPerspectiveTransform(inp_pts, outp_pts)\n",
    "    return cv2.warpPerspective(image, transform_mat, (OUT_W, OUT_H), flags=cv2.INTER_LINEAR)\n",
    "\n",
    "def find_rect_by_two_lines(line_ichi: tuple[tuple[int, int], tuple[int, int]], k2: float, b2: float, size: int) -> tuple[tuple[int, int], tuple[int, int], tuple[int, int], tuple[int, int]]:\n",
    "    k1, b1 = line_koeff(line_ichi)\n",
    "    sanme_point = find_intersection(k1, b1, k2, b2, line_ichi[0][0], size)\n",
    "    yonme_point = find_intersection(k1, b1, k2, b2, line_ichi[1][0], size)\n",
    "    sanme_point = restrict(sanme_point[0], 0, size-1), restrict(sanme_point[1], 0, size-1)\n",
    "    yonme_point = restrict(yonme_point[0], 0, size-1), restrict(yonme_point[1], 0, size-1)\n",
    "    return normalize_fit_tetragon((line_ichi[0], line_ichi[1], sanme_point, yonme_point), size)\n",
    "\n",
    "# there we have two lines\n",
    "# with that information we can find intersections\n",
    "# size is the image limit\n",
    "def find_tetragon_hinted(line_ichi: tuple[tuple[int, int], tuple[int, int]], line_ni: tuple[tuple[int, int], tuple[int, int]], size: int) -> tuple[tuple[int, int], tuple[int, int], tuple[int, int], tuple[int, int]]:\n",
    "    k2, b2 = line_koeff(line_ni)\n",
    "    return find_rect_by_two_lines(line_ichi, k2, b2, size)\n",
    "\n",
    "def get_rect_hinted(image: np.ndarray, line_ichi: tuple[tuple[int, int], tuple[int, int]], line_ni: tuple[tuple[int, int], tuple[int, int]], size: int) -> np.ndarray:\n",
    "    return extract_maiha(image, find_tetragon_hinted(line_ichi, line_ni, size))\n",
    "\n",
    "def is_valid_rect(rect: tuple[tuple[int, int], tuple[int, int], tuple[int, int], tuple[int, int]], size: int) -> bool:\n",
    "    for x in rect:\n",
    "        if x[0] >= size or x[1] >= size or x[0] < 0 or x[1] < 0:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def rm_background(image: np.ndarray) -> np.ndarray:\n",
    "    lower = np.array([128, 64, 128])\n",
    "    upper = np.array([255, 255, 255])\n",
    "    thresh = cv2.inRange(image, lower, upper)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (10, 10))\n",
    "    morph = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "    mask = 255 - morph\n",
    "    result = cv2.bitwise_and(image, image, mask=mask)\n",
    "    return result\n",
    "\n",
    "def compute_image_score(image: np.ndarray, hght: float) -> float: # we should keep it as low as possible\n",
    "    #no_green_image: np.ndarray = image.copy()\n",
    "    #no_green_image[:, :, 1] = 0\n",
    "    #return float(np.sum(image, dtype=float) + 1) / (image.shape[0] * image.shape[1] * image.shape[2])\n",
    "\n",
    "    nonz = float(np.count_nonzero(image))\n",
    "    all_pix = image.shape[0] * image.shape[1] * image.shape[2]\n",
    "    score = ((hght) ** (1)) * ((all_pix - nonz + 1))\n",
    "\n",
    "    cv2.imshow('score {}, h:{}, nonz: {}, all: {}'.format(int(score), int(hght), int(nonz), int(all_pix)), image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    return score # return black only\n",
    "\n",
    "# just for testing purposes\n",
    "def find_rect_no_hint(image: np.ndarray, line: tuple[tuple[int, int], tuple[int, int]], size: int) -> tuple[tuple[int, int], tuple[int, int], tuple[int, int], tuple[int, int]]:\n",
    "    b_step = 2 ** 8\n",
    "    k1, b1 = line_koeff(line)\n",
    "    result: tuple[tuple[int, int], tuple[int, int], tuple[int, int], tuple[int, int]] = (0, 0), (0, 0), (0, 0), (0, 0)\n",
    "    k_c, b_c = k1, b1\n",
    "    scoring_image = rm_background(image)\n",
    "    while b_step >= 1:\n",
    "        kl, bl = k_c, b_c + b_step # low\n",
    "        kh, bh = k_c, b_c - b_step # high\n",
    "        rect_l, rect_h = find_rect_by_two_lines(line, kl, bl, size), find_rect_by_two_lines(line, kh, bh, size)\n",
    "        img_l = extract_maiha(scoring_image, rect_l)\n",
    "        img_h = extract_maiha(scoring_image, rect_h)\n",
    "        score_l = compute_image_score(img_l, abs(b1 - bl)) # TODO NEEDS HEAVY ADJUSTMENTS\n",
    "        score_h = compute_image_score(img_h, abs(b1 - bh)) # CURRENT BUG!!!!!!\n",
    "        if score_l < score_h:\n",
    "            k_c, b_c = kl, bl\n",
    "            result = rect_l\n",
    "        else:\n",
    "            k_c, b_c = kh, bh\n",
    "            result = rect_h\n",
    "        b_step = int(b_step / 2)\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_rect_no_hint(image: np.ndarray, line: tuple[tuple[int, int], tuple[int, int]], size: int) -> np.ndarray:\n",
    "\n",
    "    return None\n",
    "\n",
    "def process_image(image: np.ndarray, size: int) -> np.ndarray:\n",
    "    lines = find_candidate_lines(image)\n",
    "    if 0 and len(lines) > 1:\n",
    "        return get_rect_hinted(image, lines[0], lines[1], size)\n",
    "    elif len(lines) >= 1:\n",
    "        return get_rect_no_hint(image, lines[0], size)\n",
    "    return cv2.resize(image, (OUT_W, OUT_H))\n",
    "\n",
    "def process_image_get_lines(image: np.ndarray, size: int) -> tuple[tuple[int, int], tuple[int, int], tuple[int, int], tuple[int, int]]:\n",
    "    lines = find_candidate_lines(image)\n",
    "    if 0 and len(lines) > 1:\n",
    "        res = find_tetragon_hinted(lines[0], lines[1], size)\n",
    "        for x in res:\n",
    "            if x[0] >= size or x[1] >= size or x[0] < 0 or x[1] < 0:\n",
    "                print(\"hinted failure\", x[0], x[1], file=stderr)\n",
    "        return res\n",
    "    elif len(lines) >= 1:\n",
    "        res = find_rect_no_hint(image, lines[0], size)\n",
    "        for x in res:\n",
    "            if x[0] >= size or x[1] >= size or x[0] < 0 or x[1] < 0:\n",
    "                print(\"no hint failure\", x[0], x[1], file=stderr)\n",
    "        return res\n",
    "    return (0, 0), (0, size), (size, size), (size, 0)\n",
    "\n",
    "def show_draw_lines(path: str):\n",
    "    image = cv2.imread(path)\n",
    "    image = cv2.resize(image, (1600, 1600))\n",
    "    lines = find_candidate_lines(image)\n",
    "    for line in lines:\n",
    "        cv2.line(image, line[0], line[1], color=(255, 0, 0), thickness=2)\n",
    "\n",
    "    PIL.Image.fromarray(image).show()\n",
    "\n",
    "\n",
    "def process_folder_draw_lines(folder: str, target_folder: str):\n",
    "    files = os.listdir(folder)\n",
    "    for filename in files[:100]:\n",
    "        image = cv2.imread(os.path.join(folder, filename))\n",
    "        image = cv2.resize(image, (1024, 1024))\n",
    "        lines = find_candidate_lines(image)\n",
    "        for line in lines:\n",
    "            cv2.line(image, line[0], line[1], color=(0, 0, 255), thickness=2)\n",
    "        cv2.imwrite(os.path.join(target_folder, filename), image)\n",
    "\n",
    "def process_folder_draw_tetra(folder: str, target_folder: str):\n",
    "    files = os.listdir(folder)\n",
    "    for filename in files[:10]:\n",
    "        image = cv2.imread(os.path.join(folder, filename))\n",
    "        image = cv2.resize(image, (1024, 1024))\n",
    "        print(filename, file=stderr)\n",
    "        tetra = process_image_get_lines(image, 1024)\n",
    "        #cv2.drawContours(image, [approx], -1, (0, 255, 0), 2)\n",
    "        #print(np.array(tetra))\n",
    "        cv2.drawContours(image, [np.array(sort_counterclock(tetra), dtype=np.int)], -1, (0, 0, 255), 2)\n",
    "        cv2.imwrite(os.path.join(target_folder, filename), image)\n",
    "\n",
    "def process_folder_extract(folder: str, target_folder: str):\n",
    "    files = os.listdir(folder)\n",
    "    for filename in files[:10]:\n",
    "        image = cv2.imread(os.path.join(folder, filename))\n",
    "        image = cv2.resize(image, (1024, 1024))\n",
    "        print(filename, file=stderr)\n",
    "        extracted = process_image(image, 1024)\n",
    "        cv2.imwrite(os.path.join(target_folder, filename), extracted)\n",
    "\n",
    "\n",
    "#show_draw_lines(\"RiceLeafs/train/Healthy/IMG_20190419_123646.jpg\")\n",
    "#process_folder_draw_lines(\"RiceLeafs/train/Healthy\", \"test\")\n",
    "#process_folder_extract(\"RiceLeafs/train/Healthy\", \"test\")\n",
    "process_folder_draw_tetra(\"RiceLeafs/train/Healthy\", \"test_lines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cc85df",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def warpImage(image, corners, target):\n",
    "    #mat = cv2.CreateMat(3, 3, cv2.CV_32F)\n",
    "    mat = np.zeros((3, 3), dtype=np.float64)\n",
    "    cv2.getPerspectiveTransform(corners, target, mat)\n",
    "    #out = cv2.CreateMat(height, width, cv2.CV_8UC3)\n",
    "    out = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "    cv2.warpPerspective(image, out, mat, cv2.INTER_CUBIC)\n",
    "    return out\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    width, height = 400, 250\n",
    "    corners = [(171,72),(331,93),(333,188),(177,210)]\n",
    "    target = [(0,0),(width,0),(width,height),(0,height)]\n",
    "    image = cv2.LoadImageM('fries.jpg')\n",
    "    out = warpImage(image, corners, target)\n",
    "    cv2.SaveImage('fries_warped.jpg', out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26cd48c7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import Input, Lambda, Dense, Flatten,GlobalAveragePooling2D,BatchNormalization,Dropout,Activation\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report, log_loss, accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39e52a2b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BrownSpot', 'Healthy', 'Hispa', 'LeafBlast']\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "train_dir = 'RiceLeafs/train'\n",
    "test_dir = 'RiceLeafs/validation'\n",
    "classes=[]\n",
    "for file in os.listdir(train_dir):\n",
    "    classes+=[file]\n",
    "print(classes)\n",
    "print(len(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82b9dc52",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "brownSpot = [train_dir + '/BrownSpot/' + img for img in os.listdir(train_dir + '/BrownSpot')[:9]]\n",
    "healthy = [train_dir  + '/Healthy/' + img for img in os.listdir(train_dir + '/Healthy')[:9]]\n",
    "hispa = [train_dir  + '/Hispa/' + img for img in os.listdir(train_dir + '/Hispa')[:9]]\n",
    "leafBlast = [train_dir  + '/LeafBlast/' + img for img in os.listdir(train_dir + '/LeafBlast')[:9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c805c31f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset=[]\n",
    "shape=(600,100)\n",
    "count=0\n",
    "for file in os.listdir(train_dir):\n",
    "    path=os.path.join(train_dir,file)\n",
    "    t=0\n",
    "    for im in os.listdir(path):\n",
    "        image=load_img(os.path.join(path,im), grayscale=False, color_mode='rgb', target_size=shape)\n",
    "        image=img_to_array(image)\n",
    "        image=image/255.0\n",
    "        dataset+=[[image,count]]\n",
    "        t+=1\n",
    "    count=count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4fe3c6d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "testset=[]\n",
    "count=0\n",
    "for file in os.listdir(test_dir):\n",
    "    path=os.path.join(test_dir,file)\n",
    "    t=0\n",
    "    for im in os.listdir(path):\n",
    "        image=load_img(os.path.join(path,im), grayscale=False, color_mode='rgb', target_size=shape)\n",
    "        image=img_to_array(image)\n",
    "        image=image/255.0\n",
    "        testset+=[[image,count]]\n",
    "        t+=1\n",
    "    count=count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5af4aa16",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2147, 600, 100, 3)\n",
      "(537, 600, 100, 3)\n",
      "(2147, 4)\n",
      "(537, 4)\n"
     ]
    }
   ],
   "source": [
    "data,trainlabels = zip(*dataset)\n",
    "test,testlabels = zip(*testset)\n",
    "labels1=to_categorical(trainlabels)\n",
    "labels=np.array(labels1)\n",
    "data=np.array(data)\n",
    "test=np.array(test)\n",
    "trainx,testx,trainy,testy=train_test_split(data,labels,test_size=0.2,random_state=42)\n",
    "print(trainx.shape)\n",
    "print(testx.shape)\n",
    "print(trainy.shape)\n",
    "print(testy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d74fee8c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(horizontal_flip=True,vertical_flip=True,rotation_range=30,zoom_range=0.2,\n",
    "                             width_shift_range=0.1,height_shift_range=0.2,shear_range=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "992c7b1a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Conv2D_Model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 598, 98, 16)       448       \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 299, 49, 16)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 297, 47, 32)       4640      \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 148, 23, 32)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 146, 21, 64)       18496     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 73, 10, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 46720)             0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               5980288   \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 4)                 1028      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,037,924\n",
      "Trainable params: 6,037,924\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(16,(3,3),activation = 'relu',input_shape = (600,100,3)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(32,(3,3),activation = 'relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64,(3,3),activation = 'relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128,activation = 'relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(256,activation = 'relu'),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(4,activation = 'softmax')\n",
    "\n",
    "],    name = 'Conv2D_Model')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f344380",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.001 #@param {type:\"number\"}\n",
    "\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "297c3953",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "68/68 [==============================] - 67s 981ms/step - loss: 1.3248 - accuracy: 0.4276 - val_loss: 1.2438 - val_accuracy: 0.4618\n",
      "Epoch 2/10\n",
      "68/68 [==============================] - 62s 913ms/step - loss: 1.2812 - accuracy: 0.4453 - val_loss: 1.1357 - val_accuracy: 0.5363\n",
      "Epoch 3/10\n",
      "68/68 [==============================] - 62s 909ms/step - loss: 1.2813 - accuracy: 0.4364 - val_loss: 1.2170 - val_accuracy: 0.4618\n",
      "Epoch 4/10\n",
      "68/68 [==============================] - 63s 926ms/step - loss: 1.2582 - accuracy: 0.4341 - val_loss: 1.2704 - val_accuracy: 0.4618\n",
      "Epoch 5/10\n",
      "68/68 [==============================] - 61s 900ms/step - loss: 1.2061 - accuracy: 0.4667 - val_loss: 1.2558 - val_accuracy: 0.5214\n",
      "Epoch 6/10\n",
      "68/68 [==============================] - 61s 898ms/step - loss: 1.2059 - accuracy: 0.4793 - val_loss: 1.1701 - val_accuracy: 0.5307\n",
      "Epoch 7/10\n",
      "68/68 [==============================] - 62s 910ms/step - loss: 1.1821 - accuracy: 0.5049 - val_loss: 1.1710 - val_accuracy: 0.5307\n",
      "Epoch 8/10\n",
      "68/68 [==============================] - 62s 915ms/step - loss: 1.1505 - accuracy: 0.5095 - val_loss: 1.0227 - val_accuracy: 0.6201\n",
      "Epoch 9/10\n",
      "68/68 [==============================] - 63s 932ms/step - loss: 1.0940 - accuracy: 0.5482 - val_loss: 1.0018 - val_accuracy: 0.6052\n",
      "Epoch 10/10\n",
      "68/68 [==============================] - 63s 923ms/step - loss: 1.1273 - accuracy: 0.5203 - val_loss: 1.0803 - val_accuracy: 0.5587\n"
     ]
    }
   ],
   "source": [
    "his=model.fit(datagen.flow(trainx,trainy,batch_size=32),validation_data=(testx,testy),epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d24a58b5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_acc = his.history['accuracy']\n",
    "value_acc = his.history['val_accuracy']\n",
    "get_loss = his.history['loss']\n",
    "validation_loss = his.history['val_loss']\n",
    "\n",
    "epochs = range(len(get_acc))\n",
    "plt.plot(epochs, get_acc, 'r', label='Accuracy of Training data')\n",
    "plt.plot(epochs, value_acc, 'b', label='Accuracy of Validation data')\n",
    "plt.title('Training vs validation accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f3e66c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}